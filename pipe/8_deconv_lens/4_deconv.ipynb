{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0747bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Config dir: /scratch/COSMOULINE/ECAM_J0818-2613/config/ ###\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import readlink\n",
    "from pathlib import Path\n",
    "from astropy.io import fits\n",
    "import h5py\n",
    "from copy import deepcopy\n",
    "from matplotlib import colors\n",
    "from       matplotlib.widgets        import  Slider\n",
    "\n",
    "\n",
    "import sys\n",
    "if sys.path[0]:\n",
    "    # if ran as a script, append the parent dir to the path\n",
    "    sys.path.append(os.path.dirname(sys.path[0]))\n",
    "else:\n",
    "    # if ran interactively, append the parent manually as sys.path[0] \n",
    "    # will be emtpy.\n",
    "    sys.path.append('..')\n",
    "sys.path.append('..')\n",
    "    \n",
    "# import cosmouline stuff\n",
    "from config import dbbudir, imgdb, settings, configdir, computer,\\\n",
    "                   psfsfile, extracteddir\n",
    "from modules.variousfct import proquest, readimagelist, mterror,\\\n",
    "                               backupfile, notify\n",
    "from modules.kirbybase import KirbyBase\n",
    "from settings_manager import importSettings\n",
    "\n",
    "db = KirbyBase(imgdb)  \n",
    "\n",
    "askquestions = settings['askquestions']\n",
    "workdir = settings['workdir']\n",
    "decname = settings['decname']\n",
    "decnormfieldname = settings['decnormfieldname']\n",
    "decpsfnames = settings['decpsfnames']\n",
    "decobjname = settings['decobjname']\n",
    "refimgname_per_band = settings['refimgname_per_band']\n",
    "setnames = settings['setnames']\n",
    "\n",
    "# import the right deconvolution identifiers:\n",
    "scenario = \"normal\"\n",
    "if len(sys.argv)==2:\n",
    "    scenario = \"allstars\"\n",
    "    decobjname = sys.argv[1]\n",
    "if settings['update']:\n",
    "    scenario = \"update\"\n",
    "    askquestions = False\n",
    "\n",
    "    \n",
    "# deconvolution identifiers. Lists because one per setname.\n",
    "deckeyfilenums, deckeynormuseds, deckeys, decdirs,\\\n",
    "           decfiles, decskiplists, deckeypsfuseds, ptsrccats = importSettings(scenario)\n",
    "\n",
    "# the most important one is probably \"decfiles\", which is a list of hdf5 files (one per setname)\n",
    "# containing all the data needed for the deconvolution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b2858d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import starred stuff\n",
    "from starred.deconvolution.deconvolution import Deconv\n",
    "from starred.deconvolution.loss import Loss\n",
    "from starred.utils.optimization import Optimizer\n",
    "from starred.deconvolution.parameters import ParametersDeconv\n",
    "from starred.utils.noise_utils import propagate_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f63bd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "M = 4 # number of point sources \n",
    "method = 'trust-constr'\n",
    "method_ada = 'adabelief'\n",
    "# lambdas normalized in weight map.\n",
    "lambda_scales = 1.\n",
    "lambda_hf = 1.\n",
    "convolution_method = 'fft'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cb4d91",
   "metadata": {},
   "source": [
    "## Tune background and image positions with best seeing frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6dc337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "def getData(decfile):\n",
    "    with h5py.File(decfile, 'r') as f:\n",
    "        data = np.array(f['stamps'])\n",
    "        noisemap = np.array(f['noisemaps'])\n",
    "        s = np.array(f['psfs'])\n",
    "    \n",
    "    im_size = data.shape[1]\n",
    "    im_size_up = s.shape[1]\n",
    "    epochs = data.shape[0]\n",
    "    subsampling_factor = im_size_up // im_size\n",
    "    \n",
    "    return data, noisemap, s, (im_size, im_size_up, subsampling_factor, epochs)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69ca427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the frist two stamps\n",
    "for setname, decfile in zip(setnames, decfiles):\n",
    "    data, noisemap, s, (im_size, im_size_up, subsampling_factor, epochs) = getData(decfile)\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8,8))\n",
    "    fraction = 0.046\n",
    "    pad = 0.04\n",
    "    plt.suptitle(setname)\n",
    "    plt.rc('font', size=12)           \n",
    "    axs[0].tick_params(axis='both', which='major', labelsize=10)\n",
    "    axs[1].tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "    fig.colorbar(axs[0].imshow(data[0,:,:],\n",
    "                               norm=colors.SymLogNorm(linthresh=1e3)),\n",
    "                               ax=axs[0], fraction=fraction, pad=pad)\n",
    "    fig.colorbar(axs[1].imshow(data[1,:,:]/noisemap[1,:,:]**0.5,\n",
    "                               norm=colors.SymLogNorm(linthresh=1e3)), \n",
    "                               ax=axs[1], fraction=fraction, pad=pad)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6ed9997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see some psfs\n",
    "fig, axs = plt.subplots(5,7, figsize=(9,7))\n",
    "for im, ax in zip(s, axs.flatten()):\n",
    "    ax.imshow(im)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35ead92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see some noise maps\n",
    "fig, axs = plt.subplots(4,7, figsize=(14,7))\n",
    "for im, ax in zip(noisemap, axs.flatten()):\n",
    "    ax.imshow(im**0.5)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "872792d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Cannot change to a different GUI toolkit: notebook. Using qt5 instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f4abefc9e90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameter initialization\n",
    "\n",
    "# image positions (read these from a matplotlib plot above)\n",
    "off = im_size // 2 # removing im_size / 2 because starred has (0,0) = center\n",
    "# you will probably need to adjust your offset\n",
    "off -= 0.9\n",
    "xs = np.array([22.6, 23.7, 44.1, 42.2]) - off\n",
    "ys = np.array([38.3, 34.8, 18.6, 44.2]) - off\n",
    "\n",
    "initial_c_x = xs * subsampling_factor \n",
    "initial_c_y = ys * subsampling_factor \n",
    "# intensity per point:\n",
    "# adjust these from running this cell iteratively\n",
    "initial_a = 1.65*np.array(epochs*[60000., 60000., 10000., 12761.])\n",
    "\n",
    "# no need to do anything past here, setting up the deconv in a standard way.\n",
    "# provide a normalization for the image, makes things numerically more tractable:\n",
    "scale = data.max()\n",
    "initial_a /= scale\n",
    "# we will also provide the Deconvolution class with this scale at the end of this cell.\n",
    "\n",
    "# initial background:\n",
    "initial_h = np.zeros((im_size_up**2))\n",
    "\n",
    "\n",
    "\n",
    "# dictionary containing the parameters of deconvolution.\n",
    "# (The translations dx, dy are set to zero for the first epoch.\n",
    "# Thus we only initialize (epochs-1) of them.)\n",
    "kwargs_init = {\n",
    "    'kwargs_analytic': {\n",
    "                        'c_x': initial_c_x,\n",
    "                        'c_y': initial_c_y,\n",
    "                        'dx' : np.ravel([0. for _ in range(epochs-1)]),\n",
    "                        'dy' : np.ravel([0. for _ in range(epochs-1)]),\n",
    "                        'a'  : initial_a},\n",
    "    'kwargs_background': {'h': initial_h,\n",
    "                          'mean': np.ravel([0. for _ in range(epochs)])},\n",
    "}\n",
    "# same as above, providing fixed parameters:\n",
    "kwargs_fixed = {\n",
    "    'kwargs_analytic': {\n",
    "        'c_x': initial_c_x, \n",
    "        'c_y': initial_c_y, \n",
    "        # 'a'  : initial_a\n",
    "    },\n",
    "    'kwargs_background': {'h': initial_h},\n",
    "}\n",
    "\n",
    "\n",
    "# boundaries.\n",
    "kwargs_up = {\n",
    "    'kwargs_analytic': {'c_x': list(initial_c_x+3),\n",
    "                        'c_y': list(initial_c_y+3),\n",
    "                        'dx' : [5 for _ in range(epochs-1)],\n",
    "                        'dy' : [5 for _ in range(epochs-1)],\n",
    "                         'a': list([np.inf for i in range(M*epochs)]) \n",
    "                       },\n",
    "    'kwargs_background': {'h': list([np.inf for i in range(0, im_size_up**2)]),\n",
    "                          'mean': [np.inf for _ in range(epochs)]\n",
    "                           },\n",
    "}\n",
    "\n",
    "kwargs_down = {\n",
    "    'kwargs_analytic': {'c_x': list(initial_c_x-3),\n",
    "                        'c_y': list(initial_c_y-3),\n",
    "                        'dx' : [-5 for _ in range(epochs-1)],\n",
    "                        'dy' : [-5 for _ in range(epochs-1)],\n",
    "                         'a': list([0 for i in range(M*epochs)]) },\n",
    "    'kwargs_background': {'h': list([-np.inf for i in range(0, im_size_up**2)]),\n",
    "                          'mean': [-np.inf for _ in range(epochs)]\n",
    "                           },\n",
    "        }\n",
    "\n",
    "# Initializing the model\n",
    "model = Deconv(image_size=im_size, \n",
    "               number_of_sources=M, \n",
    "               scale=scale, \n",
    "               upsampling_factor=subsampling_factor, \n",
    "               epochs=epochs, \n",
    "               psf=s, \n",
    "               convolution_method=convolution_method)\n",
    "\n",
    "# and the class handling the parameters:\n",
    "# (fixed or not, boundaries ...)\n",
    "parameters = ParametersDeconv(model, kwargs_init, \n",
    "                              kwargs_fixed, \n",
    "                              kwargs_up=kwargs_up, \n",
    "                              kwargs_down=kwargs_down)\n",
    "\n",
    "\n",
    "# first look at what our model is like given our initial guess:\n",
    "%matplotlib notebook\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(model.model(kwargs_init)[0] - data[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57c0f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute noise level in starlet space\n",
    "# MAKE SURE TO USE A NOISEMAP WITHOUT WEIRD THINGS\n",
    "# (e.g., masked region with huge values)\n",
    "W = propagate_noise(model, noisemap, kwargs_init, wavelet_type_list=['starlet'], \n",
    "                    method='SLIT', num_samples=200, seed=1, likelihood_type='chi2', \n",
    "                    verbose=False, upsampling_factor=subsampling_factor, debug=False)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acf61b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some function useful later\n",
    "\n",
    "def viewModel(kwargs):\n",
    "    output = model.model(kwargs)\n",
    "    \n",
    "    # setup for first epoch\n",
    "    deconvs = [model.getDeconvolved(kwargs, i) for i in range(len(output))]\n",
    "    deconv, h = deconvs[0]\n",
    "    fig, axs = plt.subplots(2,2, figsize=(9,9))\n",
    "    for ax in axs.flatten():\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    datap = axs[0,0].imshow(data[0])\n",
    "    axs[0,0].set_title('data')\n",
    "    \n",
    "    modelp = axs[0,1].imshow(output[0])\n",
    "    axs[0,1].set_title('model')\n",
    "    \n",
    "    diffp = axs[1,0].imshow((output[0] - data[0])/noisemap[0])\n",
    "    axs[1,0].set_title('diff/noise')\n",
    "    \n",
    "    backp = axs[1,1].imshow(h)\n",
    "    axs[1,1].set_title('background')\n",
    "    \n",
    "    axcolor   = 'lightgoldenrodyellow'\n",
    "    axslider  = plt.axes([0.2, 0.05, 0.65, 0.01], facecolor=axcolor)\n",
    "    slider    = Slider(axslider, 'Epoch', 0, len(output)-1, valinit=0, valstep=1)\n",
    "    \n",
    "    \n",
    "    def press(event):\n",
    "        try:\n",
    "            button = event.button\n",
    "        except:\n",
    "            button = 'None'\n",
    "        if event.key == 'right' or button == 'down':\n",
    "            if slider.val < len(output) - 1:\n",
    "                slider.set_val(slider.val + 1)\n",
    "        elif event.key == 'left' or button == 'up':\n",
    "            if slider.val > 0:\n",
    "                slider.set_val(slider.val - 1)\n",
    "        epoch0 = int(slider.val)\n",
    "        update(slider.val)\n",
    "        fig.canvas.draw_idle()\n",
    "    \n",
    "    def reset(event):\n",
    "        slider.reset()\n",
    "    def update(val):\n",
    "        epoch0 = int(slider.val)\n",
    "        deconv, h = deconvs[epoch0]\n",
    "\n",
    "        #datap = axs[0,0].imshow(data[epoch0])\n",
    "#\n",
    "        #modelp = axs[0,1].imshow(output[epoch0])\n",
    "#\n",
    "        #diffp = axs[1,0].imshow((output[epoch0] - data[epoch0])/noisemap[epoch0])\n",
    "#\n",
    "        #backp = axs[1,1].imshow(h)\n",
    "    \n",
    "        datap.set_data(data[epoch0])\n",
    "\n",
    "        modelp.set_data(output[epoch0])\n",
    "\n",
    "        diffp.set_data((output[epoch0] - data[epoch0])/noisemap[epoch0])\n",
    "\n",
    "        backp.set_data(h)\n",
    "        \n",
    "        \n",
    "        #fig.canvas.draw_idle()\n",
    " \n",
    "    fig.canvas.mpl_connect('key_press_event', press)\n",
    "    fig.canvas.mpl_connect('scroll_event', press)\n",
    "    slider.on_changed(update)\n",
    "    plt.show(block=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1923488d",
   "metadata": {},
   "source": [
    "# HERE CHOOSE THE CELL YOU NEED\n",
    "either \n",
    "- optimize everything at once immediately\n",
    "- or optimize only point sources\n",
    "- or opitmize only backgorund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83ddb545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optax.adabelief: 100%|██████████| 3000/3000 [00:07<00:00, 428.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# Point source tuning\n",
    "\n",
    "kwargs_fixed = {\n",
    "    'kwargs_analytic': {\n",
    "    },\n",
    "    'kwargs_background':  {'h': initial_h},\n",
    "}\n",
    "\n",
    "parameters = ParametersDeconv(model, \n",
    "                              kwargs_init=kwargs_init, \n",
    "                              kwargs_fixed=kwargs_fixed, \n",
    "                              kwargs_up=kwargs_up, \n",
    "                              kwargs_down=kwargs_down)\n",
    "\n",
    "loss = Loss(data, model, parameters, noisemap**2, \n",
    "            regularization_terms='l1_starlet', \n",
    "            regularization_strength_scales=10., \n",
    "            regularization_strength_hf=10., W=W) \n",
    "\n",
    "\n",
    "optim = Optimizer(loss, parameters, method='adabelief')\n",
    "\n",
    "\n",
    "optimiser_optax_option = {\n",
    "                            'max_iterations':3000, 'min_iterations':None,\n",
    "                            'init_learning_rate':1e-4, 'schedule_learning_rate':True,\n",
    "                            'restart_from_init':True, 'stop_at_loss_increase':False,\n",
    "                            'progress_bar':True, 'return_param_history':True\n",
    "                          }           \n",
    "\n",
    "best_fit, logL_best_fit, extra_fields, runtime = optim.minimize(**optimiser_optax_option)\n",
    "\n",
    "kwargs_partial = deepcopy(parameters.best_fit_values(as_kwargs=True))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(extra_fields['loss_history'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "726459f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optax.adabelief: 100%|█████████████████████████████████████████████| 4000/4000 [00:04<00:00, 859.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Background tunning\n",
    "\n",
    "# here we fix the positions and intensites of point sources,\n",
    "# and only allow for the background to vary. \n",
    "# (pre-requisite: our initial guess is good, so we can just bring up the \n",
    "#  background without worrying about the point sources)\n",
    "kwargs_fixed = {\n",
    "    'kwargs_analytic': {\n",
    "        'c_x': initial_c_x, \n",
    "        'c_y': initial_c_y, \n",
    "        'a'  : initial_a\n",
    "    },\n",
    "    'kwargs_background': {},\n",
    "}\n",
    "\n",
    "parameters = ParametersDeconv(model, \n",
    "                              kwargs_init=kwargs_init, \n",
    "                              kwargs_fixed=kwargs_fixed, \n",
    "                              kwargs_up=kwargs_up, \n",
    "                              kwargs_down=kwargs_down)\n",
    "\n",
    "loss = Loss(data, model, parameters, sigma_2, \n",
    "            regularization_terms='l1_starlet', \n",
    "            regularization_strength_scales=1., \n",
    "            regularization_strength_hf=1., W=W) \n",
    "\n",
    "optim = Optimizer(loss, parameters, method='adabelief')\n",
    "\n",
    "\n",
    "optimiser_optax_option = {\n",
    "                            'max_iterations':3000, 'min_iterations':None,\n",
    "                            'init_learning_rate':1e-4, 'schedule_learning_rate':True,\n",
    "                            'restart_from_init':True, 'stop_at_loss_increase':False,\n",
    "                            'progress_bar':True, 'return_param_history':True\n",
    "                          }           \n",
    "\n",
    "best_fit, logL_best_fit, extra_fields, runtime = optim.minimize(**optimiser_optax_option)\n",
    "\n",
    "kwargs_partial = deepcopy(parameters.best_fit_values(as_kwargs=True))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4eee76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewModel(kwargs_partial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c54c2ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "optax.adabelief: 100%|██████████| 4000/4000 [00:09<00:00, 431.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# final tuning: allow everything to be optimized at once.\n",
    "kwargs_fixed = {\n",
    "    'kwargs_analytic': {\n",
    "    },\n",
    "    'kwargs_background': {},\n",
    "}\n",
    "\n",
    "parameters = ParametersDeconv(model, \n",
    "                              kwargs_init=kwargs_partial, \n",
    "                              kwargs_fixed=kwargs_fixed, \n",
    "                              kwargs_up=kwargs_up, \n",
    "                              kwargs_down=kwargs_down)\n",
    "\n",
    "loss = Loss(data, model, parameters, noisemap**2, \n",
    "            regularization_terms='l1_starlet', \n",
    "            regularization_strength_scales=1, \n",
    "            regularization_strength_hf=1, W=W) \n",
    "\n",
    "\n",
    "optim = Optimizer(loss, parameters, method='adabelief')\n",
    "\n",
    "\n",
    "optimiser_optax_option = {\n",
    "                            'max_iterations':4000, 'min_iterations':None,\n",
    "                            'init_learning_rate':1e-3, 'schedule_learning_rate':True,\n",
    "                            'restart_from_init':True, 'stop_at_loss_increase':False,\n",
    "                            'progress_bar':True, 'return_param_history':True\n",
    "                          }           \n",
    "\n",
    "best_fit, logL_best_fit, extra_fields, runtime = optim.minimize(**optimiser_optax_option)\n",
    "\n",
    "kwargs_final = deepcopy(parameters.best_fit_values(as_kwargs=True))\n",
    "# checking how the loss behaved ...\n",
    "plt.figure()\n",
    "plt.plot(extra_fields['loss_history'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbf0fe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewModel(kwargs_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a05fb052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving different elements of the deconvolved image\n",
    "epoch = 0\n",
    "output = model.model(kwargs_final)[epoch] \n",
    "deconv, h = model.getDeconvolved(kwargs_final, epoch)\n",
    "\n",
    "data_show = data[epoch,:,:] \n",
    "\n",
    "dif = data_show - output\n",
    "rr = np.abs(dif) / np.sqrt((noisemap**2)[epoch,:,:])\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(16,8))\n",
    "fraction = 0.046\n",
    "pad = 0.04\n",
    "font_size = 10\n",
    "ticks_size = 6\n",
    "\n",
    "plt.rc('font', size=font_size)           \n",
    "axs[0,0].set_title('Data [ADU]', fontsize=8)\n",
    "axs[0,0].tick_params(axis='both', which='major', labelsize=ticks_size)\n",
    "axs[0,1].set_title('Convolving back [ADU]', fontsize=8)\n",
    "axs[0,1].tick_params(axis='both', which='major', labelsize=ticks_size)\n",
    "axs[0,2].set_title('Map of relative residuals', fontsize=8)\n",
    "axs[0,2].tick_params(axis='both', which='major', labelsize=ticks_size)\n",
    "axs[1,0].set_title('Background [ADU]', fontsize=8)\n",
    "axs[1,0].tick_params(axis='both', which='major', labelsize=ticks_size)\n",
    "axs[1,1].set_title('Deconvolved image [ADU]', fontsize=8)\n",
    "axs[1,1].tick_params(axis='both', which='major', labelsize=ticks_size)\n",
    "axs[1,2].set_title('Narrow PSF', fontsize=8)\n",
    "axs[1,2].tick_params(axis='both', which='major', labelsize=ticks_size)\n",
    "\n",
    "fig.colorbar(axs[0,0].imshow(data_show,origin='lower', norm=colors.SymLogNorm(linthresh=5e2)), ax=axs[0,0], fraction=fraction, pad=pad)\n",
    "fig.colorbar(axs[0,1].imshow(output,origin='lower', norm=colors.SymLogNorm(linthresh=5e2)), ax=axs[0,1], fraction=fraction, pad=pad) \n",
    "fig.colorbar(axs[0,2].imshow(rr,origin='lower', norm=colors.LogNorm(vmin=0.1)), ax=axs[0,2], fraction=fraction, pad=pad) \n",
    "fig.colorbar(axs[1,0].imshow(h, norm=colors.SymLogNorm(linthresh=5e2), origin='lower'), ax=axs[1,0], fraction=fraction, pad=pad) \n",
    "fig.colorbar(axs[1,1].imshow(deconv, norm=colors.SymLogNorm(linthresh=1e2), origin='lower'), ax=axs[1,1], fraction=fraction, pad=pad) \n",
    "fig.colorbar(axs[1,2].imshow(s[epoch,:,:], norm=colors.SymLogNorm(linthresh=1e-3)), ax=axs[1,2], fraction=fraction, pad=pad);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dd5a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intensities\n",
    "A = kwargs_final['kwargs_analytic']['a']\n",
    "curves = []\n",
    "for i in range(M):\n",
    "    curves.append(A[i::M])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f35970a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there's nothing fishy:\n",
    "plt.figure()\n",
    "for i in range(M):\n",
    "    plt.plot(curves[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86c3ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the light curves.\n",
    "with h5py.File(decfile, 'r+') as f:\n",
    "    if 'light_curves' in f.keys():\n",
    "        del f['light_curves']\n",
    "    f['light_curves'] = np.array(curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5294ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "82d67367411a1dd1ecc75e5cb22d0affc17b0f4dbc8308f3928293a967e7db81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
